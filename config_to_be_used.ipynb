{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Function - Download reqd csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_ret_df(ticker):\n",
    "\n",
    "    data_source = 'alphavantage' # alphavantage or kaggle\n",
    "\n",
    "    if data_source == 'alphavantage':\n",
    "        # ====================== Loading Data from Alpha Vantage ==================================\n",
    "\n",
    "        api_key = '2KD8FZPAQ5VWR9MO'\n",
    "\n",
    "        # American Airlines stock market prices\n",
    "        ticker = ticker\n",
    "\n",
    "        # JSON file with all the stock market data for AAL from the last 20 years\n",
    "        url_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=%s&outputsize=full&apikey=%s\"%(ticker,api_key)\n",
    "\n",
    "        # Save data to this file\n",
    "        file_to_save = 'stock_market_data-%s.csv'%ticker\n",
    "\n",
    "        # If you haven't already saved data,\n",
    "        # Go ahead and grab the data from the url\n",
    "        # And store date, low, high, volume, close, open values to a Pandas DataFrame\n",
    "        if os.path.exists(file_to_save):\n",
    "            with urllib.request.urlopen(url_string) as url:\n",
    "                data = json.loads(url.read().decode())\n",
    "                # extract stock market data\n",
    "                data = data['Time Series (Daily)']\n",
    "                df = pd.DataFrame(columns=['Date','Low','High','Close','Open'])\n",
    "                for k,v in data.items():\n",
    "                    date = dt.datetime.strptime(k, '%Y-%m-%d')\n",
    "                    data_row = [date.date(),float(v['3. low']),float(v['2. high']),\n",
    "                                float(v['4. close']),float(v['1. open'])]\n",
    "                    df.loc[-1,:] = data_row\n",
    "                    df.index = df.index + 1\n",
    "            print('Data saved to : %s'%file_to_save)        \n",
    "            df.to_csv(file_to_save)\n",
    "            \n",
    "            return file_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to : stock_market_data-AAL.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.59</td>\n",
       "      <td>35.64</td>\n",
       "      <td>37.46</td>\n",
       "      <td>36.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.3</td>\n",
       "      <td>35.07</td>\n",
       "      <td>36.47</td>\n",
       "      <td>36.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.16</td>\n",
       "      <td>34.81</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.44</td>\n",
       "      <td>32.33</td>\n",
       "      <td>34.78</td>\n",
       "      <td>34.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.14</td>\n",
       "      <td>31.95</td>\n",
       "      <td>33.995</td>\n",
       "      <td>32.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    open    low    high  close\n",
       "1  36.59  35.64   37.46  36.33\n",
       "2   35.3  35.07   36.47  36.37\n",
       "3  35.16  34.81    35.9  35.08\n",
       "4  32.44  32.33   34.78  34.66\n",
       "5  33.14  31.95  33.995   32.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_to_save = download_and_ret_df('AAL')\n",
    "df1 = pd.read_csv(file_to_save,names=['ind','date','low','high','close','open'])\n",
    "df1.head()\n",
    "\n",
    "df1 = df1.drop(axis=0,columns=['ind','date'])\n",
    "df1 = df1.drop(df1.index[0])\n",
    "\n",
    "df1 = df1.reindex(columns=['open','low','high','close'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_values = df1[\"open\"].values\n",
    "plt.plot(open_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3291</th>\n",
       "      <th>3292</th>\n",
       "      <th>3293</th>\n",
       "      <th>3294</th>\n",
       "      <th>3295</th>\n",
       "      <th>3296</th>\n",
       "      <th>3297</th>\n",
       "      <th>3298</th>\n",
       "      <th>3299</th>\n",
       "      <th>3300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>36.59</td>\n",
       "      <td>35.30</td>\n",
       "      <td>35.16</td>\n",
       "      <td>32.44</td>\n",
       "      <td>33.140</td>\n",
       "      <td>31.40</td>\n",
       "      <td>31.19</td>\n",
       "      <td>32.48</td>\n",
       "      <td>31.53</td>\n",
       "      <td>32.27</td>\n",
       "      <td>...</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.25</td>\n",
       "      <td>22.60</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.44</td>\n",
       "      <td>20.90</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.40</td>\n",
       "      <td>19.30</td>\n",
       "      <td>21.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>35.64</td>\n",
       "      <td>35.07</td>\n",
       "      <td>34.81</td>\n",
       "      <td>32.33</td>\n",
       "      <td>31.950</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.12</td>\n",
       "      <td>30.24</td>\n",
       "      <td>30.60</td>\n",
       "      <td>31.82</td>\n",
       "      <td>...</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.80</td>\n",
       "      <td>22.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>21.44</td>\n",
       "      <td>20.90</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.10</td>\n",
       "      <td>19.20</td>\n",
       "      <td>19.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>37.46</td>\n",
       "      <td>36.47</td>\n",
       "      <td>35.90</td>\n",
       "      <td>34.78</td>\n",
       "      <td>33.995</td>\n",
       "      <td>33.01</td>\n",
       "      <td>33.33</td>\n",
       "      <td>32.75</td>\n",
       "      <td>32.44</td>\n",
       "      <td>32.52</td>\n",
       "      <td>...</td>\n",
       "      <td>22.29</td>\n",
       "      <td>22.60</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.31</td>\n",
       "      <td>22.50</td>\n",
       "      <td>21.75</td>\n",
       "      <td>21.05</td>\n",
       "      <td>20.58</td>\n",
       "      <td>20.53</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>36.33</td>\n",
       "      <td>36.37</td>\n",
       "      <td>35.08</td>\n",
       "      <td>34.66</td>\n",
       "      <td>32.600</td>\n",
       "      <td>32.46</td>\n",
       "      <td>32.37</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.38</td>\n",
       "      <td>32.16</td>\n",
       "      <td>...</td>\n",
       "      <td>22.21</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.58</td>\n",
       "      <td>22.20</td>\n",
       "      <td>22.16</td>\n",
       "      <td>21.50</td>\n",
       "      <td>21.01</td>\n",
       "      <td>20.21</td>\n",
       "      <td>20.50</td>\n",
       "      <td>19.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 3300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1      2      3      4       5      6      7      8      9     10  \\\n",
       "open   36.59  35.30  35.16  32.44  33.140  31.40  31.19  32.48  31.53  32.27   \n",
       "low    35.64  35.07  34.81  32.33  31.950  31.30  31.12  30.24  30.60  31.82   \n",
       "high   37.46  36.47  35.90  34.78  33.995  33.01  33.33  32.75  32.44  32.52   \n",
       "close  36.33  36.37  35.08  34.66  32.600  32.46  32.37  30.34  32.38  32.16   \n",
       "\n",
       "       ...     3291   3292   3293   3294   3295   3296   3297   3298   3299  \\\n",
       "open   ...    22.28  22.25  22.60  22.10  21.44  20.90  20.26  20.40  19.30   \n",
       "low    ...    22.10  21.80  22.40  21.75  21.44  20.90  20.18  20.10  19.20   \n",
       "high   ...    22.29  22.60  23.00  22.31  22.50  21.75  21.05  20.58  20.53   \n",
       "close  ...    22.21  22.15  22.58  22.20  22.16  21.50  21.01  20.21  20.50   \n",
       "\n",
       "        3300  \n",
       "open   21.05  \n",
       "low    19.10  \n",
       "high   21.40  \n",
       "close  19.30  \n",
       "\n",
       "[4 rows x 3300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.transpose()\n",
    "df.to_csv(\"tester.csv\",float_format=np.float32)\n",
    "df = pd.read_csv(\"tester.csv\",index_col=0)\n",
    "#df.drop(axis=0,columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = n-1\n",
    "# batch size = 30% of total\n",
    "\n",
    "batch_size = int(0.02*(df.shape[1]-1))\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = int(df.shape[1]/(0.02*(df.shape[1])))\n",
    "epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = tf.placeholder(dtype=tf.float32, shape=(None,None))\n",
    "tY = tf.placeholder(dtype=tf.float32, shape=(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = batch_size-1\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 4\n",
    "n_hidden_3 = 4\n",
    "n_out = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1':tf.Variable(np.ndarray.astype(np.random.uniform(high=.2,low=0,size=(n_features,n_hidden_1)),np.float32)),\n",
    "    'h2':tf.Variable(np.ndarray.astype(np.random.uniform(high=.001,low=0,size=(n_hidden_1,n_hidden_2)),np.float32)),\n",
    "    'h3':tf.Variable(np.ndarray.astype(np.random.uniform(high=1,low=0,size=(n_hidden_2,n_hidden_3)),np.float32)),\n",
    "    'out':tf.Variable(np.ndarray.astype(np.random.uniform(high=.001,low=0,size=(n_hidden_3,n_out)),np.float32))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1':tf.Variable(tf.ones([n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.ones([n_hidden_3])),\n",
    "    'out':tf.Variable(tf.ones([n_out]))\n",
    "}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    np.savetxt(\"weights1.csv\",sess.run(weights['h1']),delimiter=',')\n",
    "    np.savetxt(\"weights2.csv\",sess.run(weights['h2']),delimiter=',')\n",
    "    np.savetxt(\"weights3.csv\",sess.run(weights['out']),delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    hidden1 =tf.nn.leaky_relu(tf.add(tf.matmul(x,weights['h1']),biases['h1']))\n",
    "    hidden2 =tf.nn.leaky_relu(tf.add(tf.matmul(hidden1,weights['h2']),biases['h2']))\n",
    "    #hidden3 =tf.nn.leaky_relu(tf.add(tf.matmul(hidden2,weights['h3']),biases['h3']))\n",
    "    out_op = tf.nn.leaky_relu(tf.add(tf.matmul(hidden2,weights['out']),biases['out']))\n",
    "    \n",
    "    return out_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = network(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "X_train\n",
      " [[[37.86   39.38   39.26   ... 42.92   41.75   42.25  ]\n",
      "  [37.35   37.69   39.14   ... 42.1235 41.75   41.54  ]\n",
      "  [38.12   39.47   39.87   ... 43.23   43.45   42.49  ]\n",
      "  [37.93   38.14   39.54   ... 42.44   42.86   42.11  ]]\n",
      "\n",
      " [[42.86   43.5    42.55   ... 54.     53.08   52.45  ]\n",
      "  [42.56   42.76   42.325  ... 53.59   53.     52.36  ]\n",
      "  [43.46   43.81   43.48   ... 54.64   54.71   53.05  ]\n",
      "  [43.36   42.93   43.4    ... 53.88   54.32   52.59  ]]\n",
      "\n",
      " [[53.65   54.     54.35   ... 48.41   52.     51.78  ]\n",
      "  [52.34   52.21   53.45   ... 47.33   48.32   50.61  ]\n",
      "  [53.9    54.55   55.46   ... 48.89   53.19   51.78  ]\n",
      "  [53.07   53.05   54.79   ... 47.56   48.61   51.02  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[46.77   44.9    45.     ... 46.65   45.55   45.49  ]\n",
      "  [45.6    44.65   44.36   ... 46.6    45.55   45.1   ]\n",
      "  [47.44   46.78   46.64   ... 47.7    46.75   47.7   ]\n",
      "  [46.23   46.53   44.9    ... 47.47   46.47   45.2   ]]\n",
      "\n",
      " [[41.8    44.15   47.6    ... 35.15   35.2    34.28  ]\n",
      "  [41.29   41.     43.5    ... 34.85   34.8    34.2   ]\n",
      "  [44.17   44.52   47.6    ... 35.43   35.35   35.5   ]\n",
      "  [42.49   41.55   44.25   ... 35.43   35.17   35.07  ]]\n",
      "\n",
      " [[33.25   32.95   33.4    ... 33.8    33.41   33.95  ]\n",
      "  [32.78   32.93   32.6    ... 33.71   33.35   33.53  ]\n",
      "  [33.7    33.53   33.41   ... 33.91   34.07   33.98  ]\n",
      "  [33.05   33.26   32.85   ... 33.76   33.88   33.66  ]]]\n",
      "************\n",
      "X_test\n",
      " [[35.3    35.16   32.44   33.14   31.4    31.19   32.48   31.53   32.27\n",
      "  32.09   33.58   34.45   32.06   31.     31.97   32.3    33.33   36.3\n",
      "  36.44   37.93   38.8    38.7    39.6    41.41   41.37   41.23   40.84\n",
      "  42.     43.27   42.04   41.82   40.79   40.36   39.7    39.54   39.49\n",
      "  40.26   39.33   38.66   38.31   39.48   40.81   40.32   40.25   40.36\n",
      "  40.66   39.67   39.02   38.9    39.19   40.08   39.98   38.04   37.99\n",
      "  37.75   36.96   36.84   37.29   37.75   38.55   38.41   38.65   38.26\n",
      "  38.06  ]\n",
      " [35.07   34.81   32.33   31.95   31.3    31.12   30.24   30.6    31.82\n",
      "  31.81   31.87   33.53   31.98   30.82   30.81   30.75   31.59   33.41\n",
      "  35.6    36.21   37.48   38.42   38.4    39.6    40.7    41.15   40.78\n",
      "  40.27   41.85   41.99   41.19   40.7    39.65   39.7    39.32   39.42\n",
      "  39.23   39.065  38.49   38.15   38.2485 38.88   40.32   40.18   40.1504\n",
      "  40.25   39.6    39.02   38.5272 38.72   39.14   39.84   37.99   37.72\n",
      "  37.44   36.415  36.83   36.68   36.445  37.885  38.22   38.19   37.87\n",
      "  38.05  ]\n",
      " [36.47   35.9    34.78   33.995  33.01   33.33   32.75   32.44   32.52\n",
      "  32.65   33.759  35.4    33.44   32.24   32.13   32.75   33.4    36.39\n",
      "  36.85   38.1275 39.01   39.26   39.6    41.75   41.955  42.2    41.48\n",
      "  42.19   43.3    43.89   42.17   41.7668 40.86   40.545  39.97   40.06\n",
      "  40.401  40.305  39.49   39.27   39.69   41.37   41.34   40.55   40.84\n",
      "  41.04   40.7    39.82   39.15   39.39   40.19   40.71   40.1    38.21\n",
      "  38.455  37.51   37.555  37.33   37.79   38.74   38.86   38.74   38.49\n",
      "  38.62  ]\n",
      " [36.37   35.08   34.66   32.6    32.46   32.37   30.34   32.38   32.16\n",
      "  32.04   32.06   33.57   33.28   31.78   30.91   31.27   31.61   33.55\n",
      "  35.9    36.44   37.92   38.8    38.5    39.61   41.33   41.5    41.04\n",
      "  40.81   41.98   43.6    41.89   41.6    40.79   40.32   39.74   39.48\n",
      "  39.26   40.18   39.43   38.43   38.48   39.67   40.77   40.48   40.4\n",
      "  40.5    40.69   39.52   38.82   38.83   39.19   40.33   39.99   37.79\n",
      "  38.16   37.44   37.09   36.79   37.26   37.92   38.38   38.26   38.41\n",
      "  38.42  ]]\n",
      "************\n",
      "Y_train\n",
      " [[[37.86  ]\n",
      "  [37.35  ]\n",
      "  [38.12  ]\n",
      "  [37.93  ]]\n",
      "\n",
      " [[42.86  ]\n",
      "  [42.56  ]\n",
      "  [43.46  ]\n",
      "  [43.36  ]]\n",
      "\n",
      " [[53.65  ]\n",
      "  [52.34  ]\n",
      "  [53.9   ]\n",
      "  [53.07  ]]\n",
      "\n",
      " [[51.92  ]\n",
      "  [50.87  ]\n",
      "  [51.9499]\n",
      "  [50.98  ]]\n",
      "\n",
      " [[52.13  ]\n",
      "  [51.45  ]\n",
      "  [52.55  ]\n",
      "  [51.91  ]]\n",
      "\n",
      " [[44.07  ]\n",
      "  [43.9   ]\n",
      "  [44.775 ]\n",
      "  [44.4   ]]\n",
      "\n",
      " [[48.16  ]\n",
      "  [47.54  ]\n",
      "  [48.43  ]\n",
      "  [47.65  ]]\n",
      "\n",
      " [[39.99  ]\n",
      "  [38.06  ]\n",
      "  [39.99  ]\n",
      "  [38.2   ]]\n",
      "\n",
      " [[30.23  ]\n",
      "  [30.22  ]\n",
      "  [31.44  ]\n",
      "  [31.16  ]]\n",
      "\n",
      " [[38.66  ]\n",
      "  [37.91  ]\n",
      "  [39.05  ]\n",
      "  [38.36  ]]\n",
      "\n",
      " [[41.29  ]\n",
      "  [40.3   ]\n",
      "  [41.3501]\n",
      "  [40.91  ]]\n",
      "\n",
      " [[39.18  ]\n",
      "  [37.72  ]\n",
      "  [39.68  ]\n",
      "  [38.83  ]]\n",
      "\n",
      " [[40.77  ]\n",
      "  [39.59  ]\n",
      "  [41.32  ]\n",
      "  [39.75  ]]\n",
      "\n",
      " [[50.84  ]\n",
      "  [50.25  ]\n",
      "  [51.685 ]\n",
      "  [51.265 ]]\n",
      "\n",
      " [[49.67  ]\n",
      "  [49.1   ]\n",
      "  [50.94  ]\n",
      "  [50.71  ]]\n",
      "\n",
      " [[37.7   ]\n",
      "  [37.6   ]\n",
      "  [38.11  ]\n",
      "  [38.05  ]]\n",
      "\n",
      " [[41.08  ]\n",
      "  [40.76  ]\n",
      "  [42.19  ]\n",
      "  [41.87  ]]\n",
      "\n",
      " [[36.    ]\n",
      "  [35.67  ]\n",
      "  [37.1799]\n",
      "  [36.34  ]]\n",
      "\n",
      " [[23.95  ]\n",
      "  [23.4501]\n",
      "  [25.44  ]\n",
      "  [24.6   ]]\n",
      "\n",
      " [[17.18  ]\n",
      "  [16.62  ]\n",
      "  [17.2   ]\n",
      "  [16.8   ]]\n",
      "\n",
      " [[17.15  ]\n",
      "  [16.85  ]\n",
      "  [17.62  ]\n",
      "  [16.95  ]]\n",
      "\n",
      " [[13.5   ]\n",
      "  [13.47  ]\n",
      "  [14.07  ]\n",
      "  [13.9   ]]\n",
      "\n",
      " [[12.54  ]\n",
      "  [12.4   ]\n",
      "  [12.92  ]\n",
      "  [12.72  ]]\n",
      "\n",
      " [[11.34  ]\n",
      "  [11.21  ]\n",
      "  [11.73  ]\n",
      "  [11.61  ]]\n",
      "\n",
      " [[10.07  ]\n",
      "  [10.07  ]\n",
      "  [10.75  ]\n",
      "  [10.71  ]]\n",
      "\n",
      " [[ 8.85  ]\n",
      "  [ 8.68  ]\n",
      "  [ 9.16  ]\n",
      "  [ 9.1   ]]\n",
      "\n",
      " [[ 4.91  ]\n",
      "  [ 4.87  ]\n",
      "  [ 5.1   ]\n",
      "  [ 5.01  ]]\n",
      "\n",
      " [[ 5.45  ]\n",
      "  [ 5.25  ]\n",
      "  [ 5.56  ]\n",
      "  [ 5.48  ]]\n",
      "\n",
      " [[ 9.39  ]\n",
      "  [ 9.38  ]\n",
      "  [ 9.8   ]\n",
      "  [ 9.5   ]]\n",
      "\n",
      " [[ 9.5   ]\n",
      "  [ 9.21  ]\n",
      "  [ 9.5   ]\n",
      "  [ 9.24  ]]\n",
      "\n",
      " [[11.75  ]\n",
      "  [11.55  ]\n",
      "  [11.92  ]\n",
      "  [11.92  ]]\n",
      "\n",
      " [[11.    ]\n",
      "  [10.64  ]\n",
      "  [11.4   ]\n",
      "  [10.64  ]]\n",
      "\n",
      " [[ 7.32  ]\n",
      "  [ 7.08  ]\n",
      "  [ 7.45  ]\n",
      "  [ 7.33  ]]\n",
      "\n",
      " [[ 5.21  ]\n",
      "  [ 5.05  ]\n",
      "  [ 5.28  ]\n",
      "  [ 5.05  ]]\n",
      "\n",
      " [[ 4.3   ]\n",
      "  [ 3.82  ]\n",
      "  [ 4.46  ]\n",
      "  [ 3.87  ]]\n",
      "\n",
      " [[ 2.21  ]\n",
      "  [ 2.05  ]\n",
      "  [ 2.24  ]\n",
      "  [ 2.08  ]]\n",
      "\n",
      " [[ 3.81  ]\n",
      "  [ 3.7   ]\n",
      "  [ 4.14  ]\n",
      "  [ 3.97  ]]\n",
      "\n",
      " [[ 8.35  ]\n",
      "  [ 8.11  ]\n",
      "  [ 8.66  ]\n",
      "  [ 8.27  ]]\n",
      "\n",
      " [[ 4.4   ]\n",
      "  [ 3.56  ]\n",
      "  [ 4.74  ]\n",
      "  [ 3.63  ]]\n",
      "\n",
      " [[ 2.7   ]\n",
      "  [ 2.51  ]\n",
      "  [ 2.8   ]\n",
      "  [ 2.61  ]]\n",
      "\n",
      " [[ 9.57  ]\n",
      "  [ 9.27  ]\n",
      "  [ 9.72  ]\n",
      "  [ 9.62  ]]\n",
      "\n",
      " [[14.55  ]\n",
      "  [13.25  ]\n",
      "  [14.58  ]\n",
      "  [13.32  ]]\n",
      "\n",
      " [[26.48  ]\n",
      "  [25.75  ]\n",
      "  [26.53  ]\n",
      "  [26.25  ]]\n",
      "\n",
      " [[28.03  ]\n",
      "  [27.57  ]\n",
      "  [29.77  ]\n",
      "  [29.67  ]]\n",
      "\n",
      " [[47.    ]\n",
      "  [46.39  ]\n",
      "  [47.58  ]\n",
      "  [46.72  ]]\n",
      "\n",
      " [[56.62  ]\n",
      "  [55.25  ]\n",
      "  [57.4   ]\n",
      "  [55.8   ]]\n",
      "\n",
      " [[46.77  ]\n",
      "  [45.6   ]\n",
      "  [47.44  ]\n",
      "  [46.23  ]]\n",
      "\n",
      " [[41.8   ]\n",
      "  [41.29  ]\n",
      "  [44.17  ]\n",
      "  [42.49  ]]\n",
      "\n",
      " [[33.25  ]\n",
      "  [32.78  ]\n",
      "  [33.7   ]\n",
      "  [33.05  ]]]\n",
      "************\n",
      "Y_test\n",
      " [[36.59]\n",
      " [35.64]\n",
      " [37.46]\n",
      " [36.33]]\n",
      "************\n",
      "To Be Predicted\n",
      " [[36.59   35.3    35.16   32.44   33.14   31.4    31.19   32.48   31.53\n",
      "  32.27   32.09   33.58   34.45   32.06   31.     31.97   32.3    33.33\n",
      "  36.3    36.44   37.93   38.8    38.7    39.6    41.41   41.37   41.23\n",
      "  40.84   42.     43.27   42.04   41.82   40.79   40.36   39.7    39.54\n",
      "  39.49   40.26   39.33   38.66   38.31   39.48   40.81   40.32   40.25\n",
      "  40.36   40.66   39.67   39.02   38.9    39.19   40.08   39.98   38.04\n",
      "  37.99   37.75   36.96   36.84   37.29   37.75   38.55   38.41   38.65\n",
      "  38.26  ]\n",
      " [35.64   35.07   34.81   32.33   31.95   31.3    31.12   30.24   30.6\n",
      "  31.82   31.81   31.87   33.53   31.98   30.82   30.81   30.75   31.59\n",
      "  33.41   35.6    36.21   37.48   38.42   38.4    39.6    40.7    41.15\n",
      "  40.78   40.27   41.85   41.99   41.19   40.7    39.65   39.7    39.32\n",
      "  39.42   39.23   39.065  38.49   38.15   38.2485 38.88   40.32   40.18\n",
      "  40.1504 40.25   39.6    39.02   38.5272 38.72   39.14   39.84   37.99\n",
      "  37.72   37.44   36.415  36.83   36.68   36.445  37.885  38.22   38.19\n",
      "  37.87  ]\n",
      " [37.46   36.47   35.9    34.78   33.995  33.01   33.33   32.75   32.44\n",
      "  32.52   32.65   33.759  35.4    33.44   32.24   32.13   32.75   33.4\n",
      "  36.39   36.85   38.1275 39.01   39.26   39.6    41.75   41.955  42.2\n",
      "  41.48   42.19   43.3    43.89   42.17   41.7668 40.86   40.545  39.97\n",
      "  40.06   40.401  40.305  39.49   39.27   39.69   41.37   41.34   40.55\n",
      "  40.84   41.04   40.7    39.82   39.15   39.39   40.19   40.71   40.1\n",
      "  38.21   38.455  37.51   37.555  37.33   37.79   38.74   38.86   38.74\n",
      "  38.49  ]\n",
      " [36.33   36.37   35.08   34.66   32.6    32.46   32.37   30.34   32.38\n",
      "  32.16   32.04   32.06   33.57   33.28   31.78   30.91   31.27   31.61\n",
      "  33.55   35.9    36.44   37.92   38.8    38.5    39.61   41.33   41.5\n",
      "  41.04   40.81   41.98   43.6    41.89   41.6    40.79   40.32   39.74\n",
      "  39.48   39.26   40.18   39.43   38.43   38.48   39.67   40.77   40.48\n",
      "  40.4    40.5    40.69   39.52   38.82   38.83   39.19   40.33   39.99\n",
      "  37.79   38.16   37.44   37.09   36.79   37.26   37.92   38.38   38.26\n",
      "  38.41  ]]\n"
     ]
    }
   ],
   "source": [
    "def splitter(df,batch_size,total_size):\n",
    "    \n",
    "    start = 0\n",
    "    \n",
    "    X_test = df.iloc(axis=1)[0:, start+1:batch_size].values\n",
    "    \n",
    "    Y_test = df.iloc(axis=1)[0:, start:start+1].values\n",
    "    \n",
    "    \n",
    "    #X_test,Y_test = converter_values_float(X_test,Y_test)\n",
    "    \n",
    "    #print(\"X_test matrix\\n\", X_test.shape,\"\\n\",X_test)\n",
    "    #print(\"Y_test matrix\\n\", Y_test.shape,\"\\n\",Y_test)\n",
    "    \n",
    "    rem = df.shape[1]-batch_size\n",
    "    #print(\"Rem = \",rem)\n",
    "    # remaining data will be treated as train\n",
    "    #print(df.iloc[0:,batch_size:])\n",
    "    \n",
    "    X_train_list = list()\n",
    "    Y_train_list = list()\n",
    "    \n",
    "    for i in range(int(rem//batch_size)):\n",
    "        \n",
    "        start2 = batch_size\n",
    "        extend = start2*(i+1) + batch_size\n",
    "        X_train = df.iloc[0:,(start2)*(i+1):extend-1].values\n",
    "        \n",
    "        X_train_list.append(X_train)\n",
    "        \n",
    "        Y_train = df.iloc[0:, start2*(i+1):start2*(i+1)+1].values\n",
    "        \n",
    "        Y_train_list.append(Y_train)\n",
    "        \n",
    "    #print(X_train_list)\n",
    "    #print(Y_train_list)\n",
    "    #convert_train_values_float(X_train_list,Y_train_list)\n",
    "    \n",
    "    \n",
    "    return (X_train_list,X_test, Y_train_list,Y_test)\n",
    "    \n",
    "    \n",
    "\n",
    "total_size = df.shape[1]\n",
    "X_train,X_test, Y_train,Y_test=splitter(df,batch_size,total_size)\n",
    "X_test_final = df.iloc[0:,0:batch_size-1].values\n",
    "\n",
    "\n",
    "#Y,X test\n",
    "#Y,X train\n",
    "X_train = np.asarray(X_train,dtype=np.float32)\n",
    "Y_train = np.asarray(Y_train,dtype=np.float32)\n",
    "print(\"************\\nX_train\\n\",X_train)\n",
    "print(\"************\\nX_test\\n\",X_test)\n",
    "print(\"************\\nY_train\\n\",Y_train)\n",
    "print(\"************\\nY_test\\n\",Y_test)\n",
    "print(\"************\\nTo Be Predicted\\n\",X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_op = cost = tf.reduce_sum(tf.pow(logits-tY, 2))/(2*batch_size)\n",
    "loss_op = tf.reduce_sum(tf.pow(logits-tY, 2))/(2*batch_size)\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=0.05).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train\n",
    "    \n",
    "    for i in range(epoch-1):\n",
    "        _,l = sess.run([optimiser,loss_op],feed_dict={tX:X_train[i],tY:Y_train[i]})\n",
    "        # find proper loss function\n",
    "        print(\"EPOCH: \",i+1,\" LOSS: \",l)\n",
    "        loss_array.append(l)\n",
    "    print(min(loss_array))\n",
    "    # test\n",
    "    final_op_test = logits.eval(feed_dict={tX:X_test})\n",
    "    print(final_op_test)\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = []\n",
    "    deviation = np.absolute(Y_test-final_op_test)\n",
    "    for j in range(4):\n",
    "        accuracy.append(float(100-(deviation[j]/Y_test[j])*100))\n",
    "    \n",
    "        print(\"PREDICTED :\",final_op_test[j],\"ACTUAL: \",Y_test[j],\" ACCURACY: \",accuracy[j])\n",
    "        \n",
    "    \n",
    "\n",
    "    # final prediction batch\n",
    "    final_pred = logits.eval(feed_dict={tX:X_test_final})\n",
    "    print(\"FINAL PREDICTION\\n\",final_pred)\n",
    "plt.plot(loss_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
